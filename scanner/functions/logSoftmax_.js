function logSoftmax_(e,t){void 0===t&&(t=-1);var n=convertToTensor(e,"logits","logSoftmax");if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error("Log Softmax along a non-last dimension is not yet supported. Logits was rank "+n.rank+" and axis was "+t);return customGrad(function(e){var n=e.max(t,!0),r=e.sub(n),o=r.toFloat().sub(r.exp().sum(t,!0).log());return {value:o,gradFunc:function(e){var n=o.exp();return e.sub(e.sum(t,!0).mul(n))}}})(n)}